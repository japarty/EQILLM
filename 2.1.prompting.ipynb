{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T08:06:20.734883Z",
     "start_time": "2024-04-26T08:06:16.428050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set run environment (local/colab)\n",
    "# if colab install required packages and set appropriate root_path\n",
    "import os\n",
    "from pathlib import Path\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    colab = True\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    root_path = Path('/content/drive/Othercomputers/My computer/EQILLM/')\n",
    "    !pip install -r '/content/drive/Othercomputers/My computer/EQILLM/requirements.txt'\n",
    "    !pip install transformers[torch]\n",
    "    !pip install accelerate -U\n",
    "    !pip install datasets\n",
    "    !pip install torchinfo\n",
    "    import sys\n",
    "    sys.path.append(root_path)\n",
    "    #ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U\n",
    "else:\n",
    "    colab = False\n",
    "    root_path = Path('')\n",
    "\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import openai\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from eqillm import finetune, get_log_for_val, validate, val_metrics, yeelight_eow_notification, param_combinations, load_PolarIs, df_to_ds\n",
    "\n",
    "\n",
    "dotenv_config = dotenv_values(root_path / '.env')\n",
    "yeelight_notify = dotenv_config['YEELIGHT_NOTIFY'] if 'YEELIGHT_NOTIFY' in dotenv_config else False"
   ],
   "id": "96f54b79530b2f5",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_response(text, parameters, client):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"local-model\", # this field is currently unused\n",
    "        messages=create_messages(text),\n",
    "        **parameters\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def looped_prompt(texts, labels, parameters, client):\n",
    "    \n",
    "    model_name = client.models.list().data[0].dict()['id']\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    \n",
    "    prompt_log_path = root_path / 'output/prompting/prompt_log.csv'\n",
    "    response_log_path = root_path / f'output/prompting/responses/{timestamp}.csv'\n",
    "\n",
    "    # add row to prompt log\n",
    "    with open(prompt_log_path, mode='a+', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        if not os.path.exists(prompt_log_path):\n",
    "            writer.writerow(['model', 'timestamp', 'message', 'params'])\n",
    "        writer.writerow([model_name, timestamp, create_messages(), parameters])\n",
    "\n",
    "    with open(response_log_path, mode='w', newline='', encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.writer(csv_file,  delimiter='|')\n",
    "        writer.writerow(['text', 'label', 'timestamp', 'response'])\n",
    "\n",
    "        for i, (txt, label) in tqdm_notebook(enumerate(zip(texts, labels))): # iterate through each text value of first df column\n",
    "            response = get_response(txt, par, client)\n",
    "            writer.writerow([txt, label, timestamp, response])\n",
    "            csv_file.flush()"
   ],
   "metadata": {
    "id": "zjctwG-P761W",
    "ExecuteTime": {
     "end_time": "2024-04-26T08:06:20.739209Z",
     "start_time": "2024-04-26T08:06:20.734883Z"
    }
   },
   "id": "zjctwG-P761W",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "par = {'temperature': 0.7,\n",
    "       'max_tokens': 50,\n",
    "       'stop': ['Pathos'],\n",
    "       }\n",
    "\n",
    "\n",
    "\n",
    "data_path = root_path / 'data/PolarIs-Pathos.xlsx'\n",
    "polarIs_df = load_PolarIs(data_path)\n",
    "\n",
    "dataset, target_map, reversed_target_map = df_to_ds(polarIs_df, split=(0.9, 0.1), binary=True, balanced=True)\n",
    "\n",
    "shuffle = True\n",
    "if shuffle:\n",
    "    random.seed(42)\n",
    "    randomized = list(zip(dataset['train']['text'], [reversed_target_map[i] for i in dataset['train']['label']]))\n",
    "    random.shuffle(randomized)\n",
    "    val_txts = [i[0] for i in randomized]\n",
    "    val_labels = [i[1] for i in randomized]\n",
    "else:\n",
    "    val_txts, val_labels = dataset['train']['text'], [reversed_target_map[i] for i in dataset['train']['label']]\n",
    "\n",
    "def create_messages(text='_'):\n",
    "    return [\n",
    "        {\n",
    "            'role': 'system',\n",
    "             'content': \"\"\"You are an analytical tool designed to identify rhetorical pathos in text. Your task is to analyze if the speaker's intention is to elicit specific emotional response for rhetorical purposes. The only responses to consider are: 'Pathos', 'No Pathos'. Do not infer emotions not explicitly stated in the text, and do not identify emotions outside of two specified. \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Based on the analysis, is there an attempt to elicit an emotional reponse? If so, identify only one of: 'Pathos', 'No Pathos'. Do not identify emotions not listed.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Analyze the following text for pathos: {text}\"\"\"\n",
    "        },\n",
    "\n",
    "    ]"
   ],
   "metadata": {
    "id": "3GlaraGq8CIK",
    "ExecuteTime": {
     "end_time": "2024-04-26T08:06:21.739824Z",
     "start_time": "2024-04-26T08:06:20.739209Z"
    }
   },
   "id": "3GlaraGq8CIK",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T12:08:19.093135Z",
     "start_time": "2024-04-26T08:06:21.739824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = openai.OpenAI(base_url=dotenv_config['MODEL_URL'],  api_key=dotenv_config['MODEL_API_KEY'])\n",
    "looped_prompt(val_txts, val_labels, par, client)\n",
    "\n",
    "if yeelight_notify:\n",
    "    yeelight_eow_notification(dotenv_config['YEELIGHT_PORT'])\n",
    "\n",
    "# import glob"
   ],
   "id": "_5s3xCOF8C0G",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7fe15ef0bfceaa0",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

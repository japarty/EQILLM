{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1713263278350,
     "user_tz": -120,
     "elapsed": 376,
     "user": {
      "displayName": "Jakub Partyka",
      "userId": "06989008944538163465"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-04-22T07:32:01.830453Z",
     "start_time": "2024-04-22T07:32:01.824745Z"
    }
   },
   "source": [
    "# set run environment (local/colab)\n",
    "# if colab install required packages and set appropriate root_path\n",
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    colab = True\n",
    "    !pip install transformers[torch]\n",
    "    !pip install accelerate -U\n",
    "    !pip install datasets\n",
    "    !pip install torchinfo\n",
    "    #ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    root_path = '/content/drive/Othercomputers/My computer/EQILLM/'\n",
    "else:\n",
    "    colab = False\n",
    "    root_path = ''\n",
    "\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import openai\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from eqillm import finetune, get_log_for_val, validate, val_metrics, yeelight_eow_notification, param_combinations, load_PolarIs, df_to_ds\n",
    "\n",
    "\n",
    "dotenv_config = dotenv_values('.env')\n",
    "yeelight_notify = dotenv_config['YEELIGHT_NOTIFY'] if 'YEELIGHT_NOTIFY' in dotenv_config else False"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and filter"
   ],
   "metadata": {
    "collapsed": false,
    "id": "13dcd7466b7b6b81"
   },
   "id": "13dcd7466b7b6b81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T07:37:50.229009Z",
     "start_time": "2024-04-22T07:37:50.211447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_logs = pd.read_csv(os.path.join(root_path, 'output/training_logs.csv'))\n",
    "\n",
    "# shorten all runs to max 30 epochs\n",
    "training_logs = training_logs[training_logs['Epoch']<=30]\n",
    "\n",
    "# drop all runs which have less than 3 epochs\n",
    "training_logs = training_logs.groupby(['model', 'timestamp']).filter(lambda x: len(x)>=3)\n",
    "training_logs"
   ],
   "id": "bd39d041dcec5358",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot all",
   "id": "e9f85f0fad212be7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T07:32:02.501649Z",
     "start_time": "2024-04-22T07:32:01.880799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "col_to_plot = ['F1']\n",
    "\n",
    "\n",
    "def plot_all(df, col_to_plot, n, ascending=False):\n",
    "    grouped = df.groupby(['model', 'timestamp'])\n",
    "    groups_sorted_list = df.groupby(['model', 'timestamp'])[col_to_plot].max().sort_values(col_to_plot, ascending=ascending).index[:n]\n",
    "    \n",
    "    plt.figure(figsize=(30,12))\n",
    "    for name, group_df in grouped:\n",
    "        ls = ['solid', 'dashdot', 'dotted']\n",
    "        for i, col in enumerate(col_to_plot):\n",
    "            if name in groups_sorted_list:\n",
    "                plt.plot(group_df['Epoch'], group_df[col], label=f'{col}-{\"-\".join(name)}', linestyle=ls[i])\n",
    "            else:\n",
    "                plt.plot(group_df['Epoch'], group_df[col], label='_nolegend_', linestyle='dashed', alpha=0.1)\n",
    "    \n",
    "    \n",
    "    # plt.ylim(ymax=1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(col_to_plot)\n",
    "    plt.title(f'All models plot: {col_to_plot}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_all(df, col_to_plot, 10, ascending=False)"
   ],
   "id": "7dbfeec41761862b",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T07:36:44.366789Z",
     "start_time": "2024-04-22T07:36:44.360519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grouped = df.groupby(['model', 'timestamp'])\n",
    "groups_sorted_list = df.groupby(['model', 'timestamp']).max(col_to_plot).sort_values(col_to_plot, ascending=False).index[:20]\n",
    "groups_sorted_list"
   ],
   "id": "e8db61e171033367",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check latest",
   "id": "d2d7b8d5e949adaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T07:32:03.439971Z",
     "start_time": "2024-04-22T07:32:02.525392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def grouped_plot_individual(grouped, colnames, colors=['red', 'blue', 'yellow', 'green', 'purple']):\n",
    "    # Individual subplots\n",
    "    fig, axes = plt.subplots(nrows=len(grouped.groups), ncols=1, figsize=(10, 15))\n",
    "    for (group_name, group_df), ax in zip(grouped, axes):\n",
    "        ax_right = ax.twinx()\n",
    "        lines = []\n",
    "        ax_label = ''\n",
    "        ax_right_label = ''\n",
    "        for col, c in list(zip(colnames, colors)):\n",
    "            if 'Loss' in col:\n",
    "                lines+=ax_right.plot(group_df['Epoch'], group_df[col], color=c, label=col)\n",
    "                ax_right_label += col\n",
    "            else:\n",
    "                lines+=ax.plot(group_df['Epoch'], group_df[col], color=c, label=col)\n",
    "                ax_label += col\n",
    "        ax.legend(lines, [i.get_label() for i in lines], loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "last_n_runs = 5\n",
    "# pd.to_datetime(df.timestamp, format=\"%Y-%m-%d_%H-%M\").sort_values(ascending=False).unique()\n",
    "last_n = df.timestamp.sort_values(ascending=False).unique()[:last_n_runs]\n",
    "grouped = df[df['timestamp'].isin(last_n)].groupby(['model', 'timestamp'])\n",
    "cols_to_plot = ['Accuracy', 'F1', 'Training Loss', 'Validation Loss']    \n",
    "\n",
    "grouped_plot_individual(grouped, cols_to_plot)"
   ],
   "id": "743e27d26ce4e52c",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cond1 = df['model'].isin([i[0] for i in groups_sorted_list])\n",
    "cond2 = df['timestamp'].isin([i[1] for i in groups_sorted_list])\n",
    "cond3 = df['binary'] == True\n",
    "df[cond1 & cond2].groupby(['model', 'timestamp']).max('F1')"
   ],
   "metadata": {
    "id": "4c8vJ5CedHb4",
    "ExecuteTime": {
     "end_time": "2024-04-22T07:32:03.453282Z",
     "start_time": "2024-04-22T07:32:03.439971Z"
    }
   },
   "id": "4c8vJ5CedHb4",
   "execution_count": 14,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
